\documentclass[a4, 14.49pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\lhead{Uppsala University}
\cfoot{\thepage}
\rfoot{Mohammadmahdi Amini}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

\begin{document}

    \begin{titlepage}

        \begin{figure}
            \begin{minipage}{0.48\textwidth}
                \begin{flushleft}
                    \includegraphics[scale=0.5]{images/UU_LOGO.png}
                \end{flushleft}
            \end{minipage}\hfill
            \begin{minipage}{0.48\textwidth}
                \begin{flushright}
                    \includegraphics[scale=0.5]{images/UU_LOGO.png}
                \end{flushright}
            \end{minipage}
        \end{figure}

        \thispagestyle{fancy}

        \vspace{1in}

        \center

        \textsc{\large MASTER THESIS REPORT}

        \vspace{0.5in}

        \noindent\makebox[\linewidth]{\rule{\linewidth}{1.2pt}}
        \textsc{ \textbf{\large FenceX: High throughput scalable geofencing }}
        \noindent\makebox[\linewidth]{\rule{\linewidth}{1.2pt}}

        \vspace{0.5in}

        \begin{minipage}{0.48\textwidth}
            \begin{flushleft}
                \textit{Student:} \\
                Mohammadmahdi Amini \\
                mm7amini@gmail.com
            \end{flushleft}
        \end{minipage}
        \begin{minipage}{0.48\textwidth}
            \begin{flushright}
                \textit{Supervisor:} \\
                Salman Toor \\
                salman.toor@it.uu.se
            \end{flushright}
        \end{minipage}

        \vspace{2in}

        \textbf{\large Department of Information Technologies} \\

        \today

    \end{titlepage}

    \newpage

    \setcounter{page}{2}
    \tableofcontents
    \newpage

    \listoffigures
    \newpage

    \section{FenceX: High throughput scalable geofencing}

    \subsection{Note for readers}
    This document is structured in a top-down style. Which means initially the work is described with assumption that readers are familiar with all the mentioned technologies, patterns, buzz words and ... . And initially the number of references is low. Later in following sections, we tried to cover the used technologies, patterns and ... separately to the extend that context of thesis allows and most of the references are made in those sections.

    \section{Geofencing}
    TODO expand


    Geofencing essentially is checking whether a geosptial point is inside a geospatial shape or not. This can be done in two styles: push and poll.

    In poll style, a fence (geospatial shape) is queried against a database of coordinates (mover-id:geospatial point). The result is all of the coordinates that reside in the fence. This type of geofencing relies on geospatial indexing. So updating and querying the database of coordinates is CPU intensive.

    On the other hand in push style, fences are pretty much predefined. Whenever coordinates of a mover changes (a location update report arrives), an intersection check between a predefined fence and the newly reported coordinate will happen. Although no geosptial indexing is necessarily involved, the intersection checking operation is still CPU intensive.

    \begin{itemize}
        \item In poll style we have a \textbf{database of locations} and in push style, a \textbf{database of fences}.
        \item Poll style geofencing has an \textbf{on demand} nature while push style is of \textbf{real time} nature.
        \item Poll style fencing use cases: Taxi/police/ambulance dispatch. Disaster management.
        \item Push style fencing use cases: Elderly/Kid/Pet care. Gambling addiction management.
    \end{itemize}

    Please note that using poll/push terminology is an idea brought up in this thesis in order to facilitate conversations about different approaches to geofencing.

    \section{Problem statement}
    Both styles of geofencing are CPU intensive. Also, geofencing is usually implemented using databases interacting with disk and accessed over network. So a combination of natural computational latency and IO latency limits the overall throughput of systems providing geofencing services. This get worst in high load high scale use cases,
    As a remedy we can improve the computational aspect of the problem by improving the indexing algorithms. However, usually the IO latency is much more effective than operational burden. So the other approach to improve the throughput is using co-located in memory databases which do not interact with disk and are accessed through local network (localhost). In this thesis we focused on the later and tried to minimize the IO latency.

    \paragraph
    We decided to use co-located in memory databases to minimize IO. Everything will be fine until our systems faces an amount of load which can not be handled properly even after scaling up. At this stage we scale the system out and deploy more than one instance of the program. This will also help with resiliency of system; if one of the instances of program goes down or stop responding for some reason, the system can still keep serving with remaining available instances.

    \paragraph
    Until now we achieved high throughput, scalability and resiliency by minimizing IO latency and scaling the application out. Which means we ended up with a distributed system containing some components (instances of our application) that need to have same image of world, same data more precisely. The location updates or queries sent to the system by clients, can end up in any of the available instances due to load balancing. Otherwise there should be way to shard the data between instances and tell clients how to select the correct instance to which send a location update or query. We went to replication over sharding with hope of keeping clients and data management simple. So we need to some how make those instances have the same image of the world (same data) otherwise their results will be inconsistent.

    So far we have exchanged IO for the holly inconsistency issue of distributed systems. So the challenge is to keep the throughput, scalability and resiliency of geofencing system high while avoiding inconsistency among it's components.

    \subsection{functional requirements}
    Movers want their location reports be received by FenceX. This report contains the coordinate (latitude, longitude) at which mover was located when producing the report. A timestamp might be included in the report as well.

    Movers want their latest reported location to be available for being queried by their ID. (Movers want their latest reported location be memorised by system.)

    Users want to be able to send a geospatial shape (fence) to the system and in turn get movers (id:location) who are in the fence (according to their latest location report) = on demand fencing

    Users want to be able to create/update/remove/query a fence (geospatial shape) for each mover (by id).

    Movers expect each of the location reports to be checked against a potentially fence for them. Which mean for each location report for each mover, potentially a fence-point intersection should be
    calculated. The result of each intersection is if the reported coordinate located within the predefined fence. In case no fence is defined for a specific mover, no fence-point intersection should be calculated.


    \subsection{nonfunctional requirements}
    As a result of required system being a general geofencing provider, the required precision of system might vary based on the users and use cases. So FenceX should be able to ingest very high rates of location reports. Looking at potential use cases, in some the report rate could be like one report per mover every 1 minute and maximum of 1K active movers at the same time.
    Other cases might involve 1 location report per mover every 5 second with 1M active movers. So FenceX should have a very high capacity to handle load and stress.

    Since based on the use case, the required scalability of system may differ, the users of system should be able to tune the system in according to their needs. Or at least the fact that scalability requirements are not fixed over time should be factored in the design,

    Availability of FenceX should relay on modules so that if something goes wrong in one part of it, the other parts keep working. If FenceX stops receiving location reports, for instance, it should be still possible to query the saved locations by mover id and/or fence. In some cases it is acceptable to miss some location updates for some movers while in others, missing location reports is not tolerable due to high precision requirements.

    The time that takes for FenceX to answer a query by fence or calculate a fence-point intersection should not be a factor of the incoming load. In other words, the latency of those two operations should be reasonably low and should not increase as the load on the system increases. Such low latency will play a important role in the overall throughput of FenceX.


    Consistency level required for geofencing applications is not strong so eventual consistency will suffice. Once a location report has received, it might takes a fraction of time until the view of FenceX about corresponding mover changes. Before that, latest previously captured report and finalized view is valid and used. Same goes for predefined fences. So no need for distributed transactions or implementation of Saga as there is not much of intertwined that can go wrong.


    \chapter{Suggested solution}
    FenceX is a stream processing system designed and implemented into microservices. It can also be identified as a reactive distributed system that is applying event driven architecture for communication of its modules. These four big software architectural names are pretty much the same thing in the context of FenceX with their different being point of view. To avoid repeating same vocabulary over and over in this document, we use the terminology specific to each of these realms interchangeably on precisely when applicable. The listing below  illustrates words that refer to similar things but originate to different terminologies.

    \begin{itemize}
        \item[Microservice] microservice, service, operation, event processor,  processor, subscriber, publisher, module and subsystem.
        \item[Instance] instance, task
    \end{itemize}

    The exact meaning of each of the mentioned vocabulary and architectural styles will be discussed in following chapters. In case you are not familiar with any of them, please have a look at the corresponding chapters first.

    \section{overall system look}
    As you can see in the figure \ref{fig:logical-dfg}, FenceX has 6 operators. Some of them are stateful and backed by a state store and some of them are stateless.
    The exact details are as below in relation to state:

    \begin{itemize}
        \item[Stateful:] location-aggregate, fence-aggregate, location-fence-intersection
        \item[Stateless:] location-update-publisher (source), filter
    \end{itemize}

    \begin{figure}[ht]
        \caption{Logical data flow graph of FenceX - larger size available in the appendix}
        \label{fig:logical-dfg}
        \includegraphics[scale=0.2]{images/logical-data-flow-diagram.png}
        \centering
    \end{figure}

    \paragraph{location-update-publisher} plays the role of source in the FenceX stream processing pipe line. It has HTTP and RabbitMQ adaptors which is used by movers. Movers send messages or http requests in order report their latest location. Location-update-publisher turns each report into a event and publishes it into a kafka topic called \emph{location-updates}.

    \paragraph{filter}, as the name suggests, is responsible for avoiding not desired location updates to find their way further down in the stream. Checks can be against null values or invalid latitude/longitude.

    \paragraph{location-aggregate} is responsible for keeping a view of latest location of each mover by subscribing to the stream of location updates coming out of filter. It has a local database of mover-locations which applies geospatial index on the data. As a result, the query by fence is becomes possible. So location-aggregate is responsible for answering queries both by mover id and fence (geospatial shape).

    \paragraph{fence-aggregate} is responsible to keep track of predefined fences (for real time intersection scenarios).  It exposes HTTP APIs for CRUD operations. The fences are kept in an temporal KTable (kafka streams notion of table) and backed by a durable Kafka topic. In other words, each operation (CRUD) on each fence is initially a Kafka event which is later processed by fence-aggregate into a fence. The producer of those events is also fence-aggregate. In more technical terms, fence-aggregate is using event-sourcing architecture internally.

    \paragraph{fence-location-intersection} (join) has a view of predefined fences (managed by fence-aggregate) in shape of a key:value table. Key is id of mover for which the fence (value) is defined. fence-location-intersection is a join between that table and stream of location updates coming out of filter. Those location updates also has a key:value form. Key is the mover id and value is the reported location. And finally, the join operation is to check if the fence in table contains the location in the update. The result of this intersection will be events like mover X is (not) in the predefined fence.

    \paragraph{alarming} is responsible for responding to the events coming out of fence-location-intersection. Implementation of this operator is not withing boundaries of this thesis. So we won't describe its details.


    \subsection{Push and Poll legs}
    As described previously, FenceX provides two styles of geofencing, On demand and real time.

    Sending HTTP queries with a geospatial fence (query by fence) to FenceX is of on demand nature. Which means when ever a client demands a geofencing operation, they send a http query. In this style, fences are very dynamic. The fence will be checked against the whole data base of mover locations. \emph{location-aggregate} is responsible for this style of fencing. Since sending query to a system is like polling data out of it, the parts of FenceX making this possible are considered poll leg. So \emph{location-aggregate} is poll leg of FenceX.

    Calculating fence-point intersection for every location report, on the other hand, is of real time nature. For each new location report, system pushes a intersection calculation result. \emph{fence-location-intersection and fence-aggregate} carry the burden of real time fencing and they are the push leg of FenceX.
    In this style the defined fences are more static and don't change frequently over time.

    From now on, we will use the notions of push and poll leg frequently specially in the evaluation phase, Each of these legs have their own characteristics and require individual attention.

    \section{Physical data flow graph}


    \begin{figure}[ht]
        \caption{Physical data flow graph of FenceX - larger size available in the appendix}
        \label{fig:physical-dfg}
        \includegraphics[scale=0.2]{images/physical-data-flow-diagram.png}
        \centering
    \end{figure}

    Figure \ref{fig:physical-dfg} is a physical data flow graph, illustrating how possibly FenceX components can be deployed as instances of microservices containing stream processing pipe line tasks. Each group of tasks that has similar color, are one unit of deployment, an instance of a microservice.

    The combination of tasks below will be deployed as one microservice:
    \begin{itemize}
        \item{location-update-publisher} alone makes a microservice called \emph{location-update-publisher}.
        \item{filter and location-aggregate} together make a microservice called \emph{location-aggregate}. This the poll leg of FenceX.
        \item{filter, fence-aggregate and fence-location-intersection} together make a microservice called \emph{realtime-fencing}. This the push leg of FenceX.
    \end{itemize}

    You can see that each microservice exists two times in \ref{fig:physical-dfg} differed by color. It means FenseX deploys more than one instance of each microservice for scalability and resiliency purposes.
    Such characteristics will be discussed in details later.

    Below are the facts common about all FenceX microservices:
    \begin{itemize}
        \item They are implemented using Java 15.
        \item They are implemented with extensive help from Spring family frameworks and libraries like Spring boot, Spring data, Spring webflux, Spring cloud and many more.
        \item They are packaged as layered docker images so the deployment artifacts of FenceX are docker images.
        \item So far all of them expose some HTTP APIs implemented using Spring webflux on top of project reactor. As a result they are reactive applications which means they process HTTP requests in a asynchronous and non blocking manner.
        \item All of them expose a HTTP API for fetching metrics about their resource usage, JVM status, geofencing operations and ... .
        \item After successful deployment, they will be registered into a service discovery tool called Consul.
    \end{itemize}

    \subsection{Inter microservices communication}
    At the moment there is no need for HTTP communication between FenceX microservices.
    However, they can find each other's IP by querying Consul on the fly.

    The communication style of microservices in FenceX is asynchronous and event driven.
    Which means there are Kakfa topics available for publishing events and subscribing to them.
    This topics are partitioned so each instance of the microservice will subscribe to a sub set of partitions.
    This is a load sharing strategy which helps with scalability.
    \ref{fig:physical-dfg} illustrates involved (Kafka) topics in the pipeline in addition to the state stores (database)
    attached to/used by each task.
    Fundamentally each of those state stores are backed by a topic (changelog).


    \section{Microservices internal design and implentation}
    Apart from common fact stated preciously, FenceX microservices can be described in a more detailed way as following:

    \subsection{Location-update-publisher}
    Location-update-publisher is a simple Kafka publisher.
    A source in the stream processing pipeline.
    It can be exposed to outside world using both RabbitMQ and HTTP adapters.
    The adapters receive location reports.
    Reports will be mapped to the event schema that other microservices
    understand and finally the event will be published into a topic called \emph{location-updates}.
    This is a stateless service, so it can be scaled out very easy.
    Since the functionality of this service is simple, each instance doesn't need to be rich in resources.

    \subsection{location-aggregate}
    Location-aggregate is a Kafka Streams application.
    It's internal stream starts with subscribing to\emph{location-updates}, continues with a filter and finally
    aggregated into a Global KTable which is backed by an in-memory H2 database.
    Which means once a location report received by location-aggregate, it will be first checked for validity and then
    saved into an in-memory co-located database.
    The save is an update operation most of the time.
    Updating the latest captured location for a mover.
    H2 provides geospatial indexing.
    Upon each update, the index will be updated as well, so the database will become ready for being queries against a
    fence.
    By database, we mean a single big table.
    \subsubsection{co-located database}
    Usually in information systems, databases have their own cluster and deployed on machines other than the one on
    which applications are deployed.
    This is done in order to abstract away availability and scalability challenges of data(base) from developers.
    The disadvantage is that accessing such a database can only happen over network which is an IO operation with
    relatively high latency.
    Since we aimed for high throughput (low latency) geofencing in FenceX, we decided to use a databases process
    deployed tightly together with location-aggregate.
    The life cycle of this database is managed by location-aggregate.
    In fact, it's a library within the application.
    In summary, we used an embedded database.
    The direct result is that the network call for accessing this database is only within range of localhost, so the
    latency is minimum.
    \subsubsection{In memory database}
    Usually database systems are configured to use disk as storage which allows them to grow very big.
    The downside with this approach is the IO intensiveness of interacting with disk which means latency.
    Although very high throughput SSD hard drives exists, not only their price tag is high but also they are still
    not as fast as memory.
    Our goal being minimizing IO latency, the H2 database not only is configured to use memory as storage but also
    using it in an asynchronous non-blocking manner (nioMemFS).
    Which means H2 will act as if a file system exists on the memory and will access it using Java NIO technology.
    \subsubsection{Inconsistency}
    Using database systems maintaining their own dedicated cluster, means no need for being worry about the
    possible inconsistency problems.
    The nodes in the cluster need to be consistent after all, even if only they act as cold idle replicas.
    Co-located in memory databases, on the other hand, usually doesn't have any consideration for replication and/or
    consistency.
    Since we want to scale out poll leg of FenceX, facing inconsistency issues is inevitable.
    So we need a way to make each instances of location-aggregate (all of the H2 instances) have same data, same
    image of the world.
    H2 provides an out-of-the-box solution for keeping its instances consistent, even when configured to be embedded
    and in memory.
    However, after some trial and error we did not find it reliable.
    So it is up to us to keep the instances of location-aggregate consistent.
    Kafka Streams Global KTables are state stores that have same data regardless of instance.
    They are equivalent to kafka subscribers each having a different group name;
    which means they get events from all partitions.
    Normal KTables only keep a subset of world image which corresponds to the partitions they listen to.

    So if we put the H2 database underneath a Global KTable, Kafka Streams out of box keeps the H2 instances
    consistent.
    \emph{Eventually consistent} However!
    Eventually consistent means the consistency of data among instances of location-aggregate is not of ACID nature.
    Once a location update is published, the time taking for each instance to capture the location update and change
    its state accordingly, varies from an instance to another.
    This time is a factor of, for example, current load of each instance.

    Each Kafka Streams state store is backed by a topic called change log.
    This topic is durable and is saved on disk by kafka.
    Each Kafka Streams application attached on such a store, subscribe to that topic once it's up and running and
    populate it's KTables.
    That topic contains all changes that has happened to the state of application, the data in the KTable.
    So in case something happens to one of the instances (or all of them for that matter), after a restart or bringing
    a new fresh instance up, the instance recover/creates it own images of the world just by subscribing to change
    log topic.
    The subscription can be from last seen offset or from offset zero, depending on the state of underlying store.
    Sometimes the stores are back by a database using file system as storage.

    So finally we resolved the mystery of inconsistency in FenceX. Also, we covered some aspects of the work which
    makes FenceX high throughput.

    \subsubsection{realtime-fencing}
    Realtime-fencing is a Kafka Streams application responsible for keeping track of fences, receiving location updates
    and joining them.
    The join operation is fence-point intersection.
    It has two internal streams.
    One for processing location updates, and the other is for aggregating fences.
    \subsubsection{event-sourcing}
    One of the internal streams starts with subscribing to \emph{fence_event_log} topic.
    The publisher to this topic is realtime-fencing itself.
    It exposes two HTTP APIs CRUD operations on fences (only create is implemented for now).
    When create fence API, for instance, is called, apart from possible initial validations, the
    only thing that happens is publishing an (kafka) event to \emph{fence_event_log} topic.
    \emph{fenceCreatedEvent} in this case.
    No fence is created yet or saved anywhere in the system, however that's how an event-sourcing based application
    works.
    The stream that starts with subscribing to \emph{fence_event_log} topic, receives those events and aggregates
    them into a Kafka Streams KTable.
    A key:value table in which key is the ID of mover for whom the fence is defined;
    value is the WKT string describing the geospatial shape of the fence.
    Any operation on the fences should first be published as an event and later caputured by realtime-fencing up and
    running instances.
    The event will be proccesed, and a suitable change will happen on the data in the related state store.
    This approach (event-sourcing) is one of special styles of event driven architectures which feels very natural
    when implemented using Kafka Streams.
    Using this architecture leads to a eventual consistency which is usually the case with all of the event based
    systems.
    The benefit is huge potential for scalability.
    Also, the source of truth in such systems is the event_log topic rather then the database (state store).
    Whatever happens to the whole application, the state can be easily recovered by bringing a new instance of
    application up and making it subscribe to event_log topic from offset zero.
    Or in case of a bug in business logic that resulted in a wrong state, a correct state can be rebuilt after fixing
    the bug.
    These benefits come from the fact that the only durable data in this architecture is immutable facts, the
    events that has happened.
    It's worthy to mention that the event_log topic can be used as an activity log for monitoring and debugging purposes.


    In realtime-fencing the KTable keeping the fences is backed by a change log style topic similar to what we
    described about location-aggregate.
    The difference here however is that the KTable keeping fences is not global.
    So each instance of realtime-fencing has a subset of defined fences corresponding to the partitions of
    kafka topic listening to.
    Since load balancers does not know what instances is responsible for what fences at any given point in time, in
    order to query this KTable, a select all query for example, each instance that receives the query, will gather
    data from other instances.
    Such data gathering should be party implemented by us using some related features of Kafka Streams.
    In case queries more complex than select one or select all were required, this approach would not work.
    Mainly because the KTable is only a simple key:value table.

    So far we described one the internal streams of realtime-fencing, the one related to aggregating fences.

    \subsubsection{Join stream}
    The other internal stream of realtime-fencing starts with subscribing to\emph{location-updates}, continues with a
    filter and finally a join operation.
    A join between this stream of location updates and the table of fences.
    The stream is a key:value stream.
    Key is the mover ID for whom the value, location report, is published.
    A join between this stream and the fence KTable means whenever a new location update is received for a mover,
    the fence defined for that mover (if exists) will be fetched.
    Now a function can be called with the these inputs: ID of mover, the defined fence and the newly received location update.
    In our case implementation of the function is calculating if the new location is within the defined fence, A
    geospatial point-shape intersection.
    Which we call point-fence intersection.
    Output of function should be a Key:Value pair with the mover ID being the key and the value is result of
    intersecion.
    So after the join we end up with a stream of moverId:intersection-status updates.
    At the moment we have not continued the stream but ideally the status should be published into another kafka
    topic so that other operation down the stream processing pipeline can use it, like alarming.





    \nocite{*}
    \bibliography{sources}
    \bibliographystyle{IEEEtran}
\end{document}
